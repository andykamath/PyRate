{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>features</th>\n",
       "      <th>track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.559, 'energy': 0.33, 'key':...</td>\n",
       "      <td>{'album': {'album_type': 'album', 'artists': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.874, 'energy': 0.6920000000...</td>\n",
       "      <td>{'album': {'album_type': 'album', 'artists': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.759, 'energy': 0.548, 'key'...</td>\n",
       "      <td>{'album': {'album_type': 'album', 'artists': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.861, 'energy': 0.603, 'key'...</td>\n",
       "      <td>{'album': {'album_type': 'album', 'artists': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'meta': {'analyzer_version': '4.0.0', 'platfo...</td>\n",
       "      <td>{'danceability': 0.777, 'energy': 0.782, 'key'...</td>\n",
       "      <td>{'album': {'album_type': 'album', 'artists': [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            analysis  \\\n",
       "0  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "1  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "2  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "3  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "4  {'meta': {'analyzer_version': '4.0.0', 'platfo...   \n",
       "\n",
       "                                            features  \\\n",
       "0  {'danceability': 0.559, 'energy': 0.33, 'key':...   \n",
       "1  {'danceability': 0.874, 'energy': 0.6920000000...   \n",
       "2  {'danceability': 0.759, 'energy': 0.548, 'key'...   \n",
       "3  {'danceability': 0.861, 'energy': 0.603, 'key'...   \n",
       "4  {'danceability': 0.777, 'energy': 0.782, 'key'...   \n",
       "\n",
       "                                               track  \n",
       "0  {'album': {'album_type': 'album', 'artists': [...  \n",
       "1  {'album': {'album_type': 'album', 'artists': [...  \n",
       "2  {'album': {'album_type': 'album', 'artists': [...  \n",
       "3  {'album': {'album_type': 'album', 'artists': [...  \n",
       "4  {'album': {'album_type': 'album', 'artists': [...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(os.path.join('..', 'input', 'sample_analysis.json'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_to_vector(segment):\n",
    "    return [segment['duration'], segment['loudness_start'], segment['loudness_max_time'], segment['loudness_max']]\\\n",
    "        + segment['pitches'] + segment['timbre']\n",
    "\n",
    "arrs = [list(map(segment_to_vector, sample['segments'])) for sample in df['analysis']]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 18939.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# arrs = list(map(np.array, arrs))\n",
    "dim2_length = len(arrs[0][0])\n",
    "to_pad = 428 #max(map(len, arrs))\n",
    "\n",
    "for i in tqdm(range(len(arrs))):\n",
    "    if len(arrs[i]) >= to_pad:\n",
    "        arrs[i] = arrs[i][:to_pad]\n",
    "    else:\n",
    "        arrs[i] += [np.zeros(dim2_length) for _ in range(to_pad - len(arrs[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510, 428, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrs = np.array(arrs)\n",
    "arrs = arrs.reshape([*list(arrs.shape), 1])\n",
    "arrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 50\n",
    "input_image = Input(shape=arrs.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt = datetime.today() \n",
    "currentDate = ''.join([str(dt.year), str(dt.month), str(dt.day)])\n",
    "\n",
    "bestModelName = ''.join([currentDate,'AutoEncoder','.h5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 428, 28, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 428, 28, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 214, 14, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 214, 14, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 107, 7, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 107, 7, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 107, 7, 128)       147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 214, 14, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 214, 14, 64)       73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 428, 28, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 428, 28, 1)        577       \n",
      "=================================================================\n",
      "Total params: 314,625\n",
      "Trainable params: 314,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#encoder\n",
    "#input = 428 x 600 x 3\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1')(input_image) #428 x 600 x 32\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2')(pool1) #214 x 300 x 64\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3')(pool2) #107 x 150 x 128 \n",
    "\n",
    "#decoder\n",
    "conv4 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv4')(conv3) #107 x 150 x 128 \n",
    "up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128\n",
    "conv5 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv5')(up1) #214 x 300 x 64\n",
    "up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', name='conv6')(up2) #428 x 600 x 3\n",
    "\n",
    "autoencoder = Model(input_image, decoded)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss',patience=3, verbose=True)\n",
    "\n",
    "bestModelFilepath = os.path.join('.','models',bestModelName)\n",
    "checkpoint = callbacks.ModelCheckpoint(bestModelFilepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "loss = keras.losses.mse\n",
    "optimizer = keras.optimizers.Adam()\n",
    "history = keras.callbacks.History()\n",
    "\n",
    "autoencoder.compile(loss=loss, optimizer = optimizer)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state=23\n",
    "test_size=0.2\n",
    "\n",
    "X_train, X_test = train_test_split(arrs,\n",
    "                                   test_size=test_size,\n",
    "                                   random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 367 samples, validate on 41 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, batch_size=batch_size,epochs=epochs, \\\n",
    "                                    callbacks=[early_stopping, checkpoint, history], verbose=True,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
