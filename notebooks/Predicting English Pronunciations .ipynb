{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# To make sure our kernel runs all the way through and gets saved,\n",
    "# we'll trim some things back and skip training\n",
    "IS_KAGGLE = True \n",
    "\n",
    "CMU_DICT_PATH = os.path.join(\n",
    "    '../input', 'cmu-pronunciation-dictionary-unmodified-07b', 'cmudict-0.7b')\n",
    "CMU_SYMBOLS_PATH = os.path.join(\n",
    "    '../input', 'cmu-pronouncing-dictionary', 'cmudict.symbols')\n",
    "\n",
    "# Skip words with numbers or symbols\n",
    "ILLEGAL_CHAR_REGEX = \"[^A-Z-'.]\"\n",
    "\n",
    "# Only 3 words are longer than 20 chars\n",
    "# Setting a limit now simplifies training our model later\n",
    "MAX_DICT_WORD_LEN = 20\n",
    "MIN_DICT_WORD_LEN = 2\n",
    "\n",
    "\n",
    "def load_clean_phonetic_dictionary():\n",
    "\n",
    "    def is_alternate_pho_spelling(word):\n",
    "        # No word has > 9 alternate pronounciations so this is safe\n",
    "        return word[-1] == ')' and word[-3] == '(' and word[-2].isdigit() \n",
    "\n",
    "    def should_skip(word):\n",
    "        if not word[0].isalpha():  # skip symbols\n",
    "            return True\n",
    "        if word[-1] == '.':  # skip abbreviations\n",
    "            return True\n",
    "        if re.search(ILLEGAL_CHAR_REGEX, word):\n",
    "            return True\n",
    "        if len(word) > MAX_DICT_WORD_LEN:\n",
    "            return True\n",
    "        if len(word) < MIN_DICT_WORD_LEN:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    phonetic_dict = {}\n",
    "    with open(CMU_DICT_PATH, encoding=\"ISO-8859-1\") as cmu_dict:\n",
    "        for line in cmu_dict:\n",
    "\n",
    "            # Skip commented lines\n",
    "            if line[0:3] == ';;;':\n",
    "                continue\n",
    "\n",
    "            word, phonetic = line.strip().split('  ')\n",
    "\n",
    "            # Alternate pronounciations are formatted: \"WORD(#)  F AH0 N EH1 T IH0 K\"\n",
    "            # We don't want to the \"(#)\" considered as part of the word\n",
    "            if is_alternate_pho_spelling(word):\n",
    "                word = word[:word.find('(')]\n",
    "\n",
    "            if should_skip(word):\n",
    "                continue\n",
    "\n",
    "            if word not in phonetic_dict:\n",
    "                phonetic_dict[word] = []\n",
    "            phonetic_dict[word].append(phonetic)\n",
    "\n",
    "    if IS_KAGGLE: # limit dataset to 5,000 words\n",
    "        phonetic_dict = {key:phonetic_dict[key] \n",
    "                         for key in random.sample(list(phonetic_dict.keys()), 5000)}\n",
    "    return phonetic_dict\n",
    "\n",
    "phonetic_dict = load_clean_phonetic_dictionary()\n",
    "example_count = np.sum([len(prons) for _, prons in phonetic_dict.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "62aced3c8805c744c5782a7de61de9d1f9c5049e"
   },
   "source": [
    "Let's take a peek at our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOVGOROD --> N AA1 V G ER0 AA2 D\n",
      "APPOINTEE --> AH0 P OY0 N T IY1\n",
      "REPUBLICS --> R IY0 P AH1 B L IH0 K S\n",
      "SEAMEN'S --> S IY1 M AH0 N Z\n",
      "DILFORD --> D IH1 L F ER0 D\n",
      "ATLANTANS --> AE2 T L AE1 N T AH0 N Z\n",
      "ASHWORTH --> AE1 SH W ER2 TH\n",
      "BRAZELTON --> B R AH0 Z EH1 L T AH0 N\n",
      "HOBBIT --> HH AO1 B IH0 T\n",
      "SUPERBLY --> S UW1 P ER0 B L IY0\n",
      "\n",
      "After cleaning, the dictionary contains 5000 words and 5366 pronunciations (366 are alternate pronunciations).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([k+' --> '+phonetic_dict[k][0] for k in random.sample(list(phonetic_dict.keys()), 10)]))\n",
    "print('\\nAfter cleaning, the dictionary contains %s words and %s pronunciations (%s are alternate pronunciations).' % \n",
    "      (len(phonetic_dict), example_count, (example_count-len(phonetic_dict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01120130799a96aa43d169ceafc5ce9865663525"
   },
   "source": [
    "# Data Preparation\n",
    "Next, before we can do any learning, we need to come up with a way to numerically represent words and pronunciations. We'll treat words as squences of characters and pronunciations as sequences of phoneme symbols (including lexical stress markers). We can assign each character and each phoneme a number. Later we'll use these numbers to represent chars/phonemes as 1-hot vectors. Predicting phonemes from a word's letters is sometimes referred to as grapheme-to-phoneme conversion.\n",
    "\n",
    "We'll need to tell our model where a phonetic spelling starts and ends so we'll introduce 2 special start & end symbols, arbitrarily represented by the tab and newline characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "132e94f6b03eaaf77237e18ce0675db3ab2d1f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char to id mapping: \n",
      " {'': 0, '.': 1, '-': 2, \"'\": 3, 'A': 4, 'B': 5, 'C': 6, 'D': 7, 'E': 8, 'F': 9, 'G': 10, 'H': 11, 'I': 12, 'J': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'O': 18, 'P': 19, 'Q': 20, 'R': 21, 'S': 22, 'T': 23, 'U': 24, 'V': 25, 'W': 26, 'X': 27, 'Y': 28, 'Z': 29}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "START_PHONE_SYM = '\\t'\n",
    "END_PHONE_SYM = '\\n'\n",
    "\n",
    "\n",
    "def char_list():\n",
    "    allowed_symbols = [\".\", \"-\", \"'\"]\n",
    "    uppercase_letters = list(string.ascii_uppercase)\n",
    "    return [''] + allowed_symbols + uppercase_letters\n",
    "\n",
    "\n",
    "def phone_list():\n",
    "    phone_list = [START_PHONE_SYM, END_PHONE_SYM]\n",
    "    with open(CMU_SYMBOLS_PATH) as file:\n",
    "        for line in file: \n",
    "            phone_list.append(line.strip())\n",
    "    return [''] + phone_list\n",
    "\n",
    "\n",
    "def id_mappings_from_list(str_list):\n",
    "    str_to_id = {s: i for i, s in enumerate(str_list)} \n",
    "    id_to_str = {i: s for i, s in enumerate(str_list)}\n",
    "    return str_to_id, id_to_str\n",
    "\n",
    "\n",
    "# Create character to ID mappings\n",
    "char_to_id, id_to_char = id_mappings_from_list(char_list())\n",
    "\n",
    "# Load phonetic symbols and create ID mappings\n",
    "phone_to_id, id_to_phone = id_mappings_from_list(phone_list())\n",
    "\n",
    "# Example:\n",
    "print('Char to id mapping: \\n', char_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "311046c02b01ba12ef7e646b0f5426da62504220"
   },
   "source": [
    "It might be tempting to just use these id's as inputs for our model. But doing so implies a relationship between the letters/phonemes that doesn't really exist. For example, since A=4, C=6, and U=24 the implication is that A and C are somehow more alike than A and U (since 4 is closer to 6). This is obviously not the case. Instead, we can use our id mappings to convert chars and phonemes to [1-hot vectors](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "5436059c760f6065eae0165922e5ea41f1f2f44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\" is represented by:\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.] \n",
      "-----\n",
      "\"AH0\" is represented by:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "CHAR_TOKEN_COUNT = len(char_to_id)\n",
    "PHONE_TOKEN_COUNT = len(phone_to_id)\n",
    "\n",
    "\n",
    "def char_to_1_hot(char):\n",
    "    char_id = char_to_id[char]\n",
    "    hot_vec = np.zeros((CHAR_TOKEN_COUNT))\n",
    "    hot_vec[char_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "\n",
    "def phone_to_1_hot(phone):\n",
    "    phone_id = phone_to_id[phone]\n",
    "    hot_vec = np.zeros((PHONE_TOKEN_COUNT))\n",
    "    hot_vec[phone_id] = 1.\n",
    "    return hot_vec\n",
    "\n",
    "# Example:\n",
    "print('\"A\" is represented by:\\n', char_to_1_hot('A'), '\\n-----')\n",
    "print('\"AH0\" is represented by:\\n', phone_to_1_hot('AH0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cddc5cbb7f69bd855ccfb470705c6ec7f77b9538"
   },
   "source": [
    "Now that we have a way to numerically represent letters and sounds (phonemes), we can convert our entire dataset into two, big 3D matricies (tensors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "636753d1db96975b780332c40a106e79799beafb"
   },
   "outputs": [],
   "source": [
    "MAX_CHAR_SEQ_LEN = max([len(word) for word, _ in phonetic_dict.items()])\n",
    "MAX_PHONE_SEQ_LEN = max([max([len(pron.split()) for pron in pronuns]) \n",
    "                         for _, pronuns in phonetic_dict.items()]\n",
    "                       ) + 2  # + 2 to account for the start & end tokens we need to add\n",
    "\n",
    "\n",
    "def dataset_to_1_hot_tensors():\n",
    "    char_seqs = []\n",
    "    phone_seqs = []\n",
    "    \n",
    "    for word, pronuns in phonetic_dict.items():\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN, CHAR_TOKEN_COUNT))\n",
    "        for t, char in enumerate(word):\n",
    "            word_matrix[t, :] = char_to_1_hot(char)\n",
    "        for pronun in pronuns:\n",
    "            pronun_matrix = np.zeros((MAX_PHONE_SEQ_LEN, PHONE_TOKEN_COUNT))\n",
    "            phones = [START_PHONE_SYM] + pronun.split() + [END_PHONE_SYM]\n",
    "            for t, phone in enumerate(phones):\n",
    "                pronun_matrix[t,:] = phone_to_1_hot(phone)\n",
    "                \n",
    "            char_seqs.append(word_matrix)\n",
    "            phone_seqs.append(pronun_matrix)\n",
    "    \n",
    "    return np.array(char_seqs), np.array(phone_seqs)\n",
    "\n",
    "def word_to_1_hot_tensor(word):\n",
    "    word = word.upper()\n",
    "    char_seq = np.array(list(map(char_to_1_hot, word)))\n",
    "    \n",
    "            \n",
    "\n",
    "# char_seq_matrix, phone_seq_matrix = dataset_to_1_hot_tensors()        \n",
    "# print('Word Matrix Shape: ', char_seq_matrix.shape)\n",
    "# print('Pronunciation Matrix Shape: ', phone_seq_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9745b486a3f7e1feb7f141b9c351a45759119cf9"
   },
   "source": [
    "# Baseline Model\n",
    "\n",
    "Since we're dealing with sequence data, an **RNN**[[video](https://www.coursera.org/learn/nlp-sequence-models/lecture/ftkzt/recurrent-neural-network-model),[blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)] a good choice. Let's start with an **LSTM**[[video](https://www.coursera.org/learn/nlp-sequence-models/lecture/KXoay/long-short-term-memory-lstm),[blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)] based RNN.\n",
    "\n",
    "Notice that the number of characters in a word is often not the same as the number of phonemes in a pronunciation. There's no 1-to-1 mapping between our inputs and outputs. For that reason, we'll create a **sequence to sequence**[[blog](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)] model with 2 parts, an encoder and a decoder. \n",
    "\n",
    "We'll feed our word representations to the encoder one character at a time and then pass the encoder's state variables to the decoder. We need slightly different decoder setups for training vs. test time. During training, we'll feed the decoder the correct pronunciations, one phoneme at a time. At each timestep, the decoder will predict the next phoneme. During inference (test time), we don't know the correct phoneme sequence (at least in theory). So we'll feed the decoder's output from the previous time step into the next timestep as input. This is why we needed the `START_PHONE_SYM` mentioned earlier. Here's an illustration of how our network will work at test time: \n",
    "\n",
    "![](https://i.imgur.com/vzkiAnZ.png)\n",
    "\n",
    "The `phone_seq_matrix` we created above will be the input to our decoder. We'll create the decoder output by shifting all the phone sequences to the left by 1 step. The decoder outputs won't contain the start token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b035166910acd2597a5a8e22ad504fbabbf5c12e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phone_seq_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-99538d24ca49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphone_seq_matrix_decoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphone_seq_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'phone_seq_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "phone_seq_matrix_decoder_output = np.pad(phone_seq_matrix,((0,0),(0,1),(0,0)), mode='constant')[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "035480bf8bc19e150e1932534f11798046b6e931"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "\n",
    "def baseline_model(hidden_nodes = 256):\n",
    "    \n",
    "    # Shared Components - Encoder\n",
    "    char_inputs = Input(shape=(None, CHAR_TOKEN_COUNT))\n",
    "    encoder = LSTM(hidden_nodes, return_state=True)\n",
    "    \n",
    "    # Shared Components - Decoder\n",
    "    phone_inputs = Input(shape=(None, PHONE_TOKEN_COUNT))\n",
    "    decoder = LSTM(hidden_nodes, return_sequences=True, return_state=True)\n",
    "    decoder_dense = Dense(PHONE_TOKEN_COUNT, activation='softmax')\n",
    "    \n",
    "    # Training Model\n",
    "    _, state_h, state_c = encoder(char_inputs) # notice encoder outputs are ignored\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder_outputs, _, _ = decoder(phone_inputs, initial_state=encoder_states)\n",
    "    phone_prediction = decoder_dense(decoder_outputs)\n",
    "\n",
    "    training_model = Model([char_inputs, phone_inputs], phone_prediction)\n",
    "    \n",
    "    # Testing Model - Encoder\n",
    "    testing_encoder_model = Model(char_inputs, encoder_states)\n",
    "    \n",
    "    # Testing Model - Decoder\n",
    "    decoder_state_input_h = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_input_c = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, decoder_state_h, decoder_state_c = decoder(phone_inputs, initial_state=decoder_state_inputs)\n",
    "    decoder_states = [decoder_state_h, decoder_state_c]\n",
    "    phone_prediction = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    testing_decoder_model = Model([phone_inputs] + decoder_state_inputs, [phone_prediction] + decoder_states)\n",
    "    \n",
    "    return training_model, testing_encoder_model, testing_decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f922704ad733636024b0bbdd5ff3fbeb811848de"
   },
   "source": [
    "## Training\n",
    "First, we'll split off a test set so we can get a fair evaluation of our model's performance later. For Kaggle, we'll cut the test size down to just 100 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "0a1babcb42f8314cbfcccf366bdc425740cf5d4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "    \n",
    "(char_input_train, char_input_test, \n",
    " phone_input_train, phone_input_test, \n",
    " phone_output_train, phone_output_test) = train_test_split(\n",
    "    char_seq_matrix, phone_seq_matrix, phone_seq_matrix_decoder_output, \n",
    "    test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "TEST_EXAMPLE_COUNT = char_input_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db8c2a195cc644926b23f110612249af2f87b632",
    "collapsed": true
   },
   "source": [
    "Now we'll train our sequence to sequence model until it starts to overfit. We want a model that generalizes well to previously unseen examples so we'll keep the version that has the lowest validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "a5bd50fb6fb2053fe30a7cbc11e8117c985f7b07"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def train(model, weights_path, encoder_input, decoder_input, decoder_output):\n",
    "    checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, save_best_only=True)\n",
    "    stopper = EarlyStopping(monitor='val_loss',patience=3)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit([encoder_input, decoder_input], decoder_output,\n",
    "          batch_size=256,\n",
    "          epochs=100,\n",
    "          validation_split=0.2, # Keras will automatically create a validation set for us\n",
    "          callbacks=[checkpointer, stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "b7597b6a335784d17031657ca5cfd664d90c6135"
   },
   "outputs": [],
   "source": [
    "BASELINE_MODEL_WEIGHTS = os.path.join(\n",
    "    '../input', 'predicting-english-pronunciations-model-weights', 'baseline_model_weights.hdf5')\n",
    "training_model, testing_encoder_model, testing_decoder_model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f31495e07469d4c6c61552657645de96102cb053"
   },
   "source": [
    "## Prediction\n",
    "During training, at each time step, we fed our decoder the correct ouput from the previous time time step. As previously mentioned, we don't know what the *correct* ouput is at test time, only what the decoder predicted. So we need a different procedure to make predictions:\n",
    "1. Encode the input word (char sequence) as state vectors using the encoder model.\n",
    "2. Pass the encoder's state variables to the decoder. \n",
    "3. Feed the start token to the decoder to get a phoneme prediction at the first time step.\n",
    "4. Pass the updated states and 1st phoneme prediction as input to the decoder to get the 2nd predicted phoneme.\n",
    "5. Pass the updated states and 2nd phoneme into the decoder to get the 3rd phoneme and so on until the decoder predicts a stop token or we hit the maximum pronunciation length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5e5313319d19229a3275ffe42066616e6b7e2efc"
   },
   "outputs": [],
   "source": [
    "def predict_baseline(input_char_seq, encoder, decoder):\n",
    "    state_vectors = encoder.predict(input_char_seq) \n",
    "    \n",
    "    prev_phone = np.zeros((1, 1, PHONE_TOKEN_COUNT))\n",
    "    prev_phone[0, 0, phone_to_id[START_PHONE_SYM]] = 1.\n",
    "    \n",
    "    end_found = False \n",
    "    pronunciation = '' \n",
    "    while not end_found:\n",
    "        decoder_output, h, c = decoder.predict([prev_phone] + state_vectors)\n",
    "        \n",
    "        # Predict the phoneme with the highest probability\n",
    "        predicted_phone_idx = np.argmax(decoder_output[0, -1, :])\n",
    "        predicted_phone = id_to_phone[predicted_phone_idx]\n",
    "        \n",
    "        pronunciation += predicted_phone + ' '\n",
    "        \n",
    "        if predicted_phone == END_PHONE_SYM or len(pronunciation.split()) > MAX_PHONE_SEQ_LEN: \n",
    "            end_found = True\n",
    "        \n",
    "        # Setup inputs for next time step\n",
    "        prev_phone = np.zeros((1, 1, PHONE_TOKEN_COUNT))\n",
    "        prev_phone[0, 0, predicted_phone_idx] = 1.\n",
    "        state_vectors = [h, c]\n",
    "        \n",
    "    return pronunciation.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34759c3f7d8268a8df66fd0f9bd70de83cd19132"
   },
   "source": [
    "Let's do a quick manual sanity check to see how our model is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "640114347d815fb63e58a55239148575cfc4b631"
   },
   "outputs": [],
   "source": [
    "# Helper method for converting vector representations back into words\n",
    "def one_hot_matrix_to_word(char_seq):\n",
    "    word = ''\n",
    "    for char_vec in char_seq[0]:\n",
    "        if np.count_nonzero(char_vec) == 0:\n",
    "            break\n",
    "        hot_bit_idx = np.argmax(char_vec)\n",
    "        char = id_to_char[hot_bit_idx]\n",
    "        word += char\n",
    "    return word\n",
    "\n",
    "\n",
    "# Some words have multiple correct pronunciations\n",
    "# If a prediction matches any correct pronunciation, consider it correct.\n",
    "def is_correct(word,test_pronunciation):\n",
    "    correct_pronuns = phonetic_dict[word]\n",
    "    for correct_pronun in correct_pronuns:\n",
    "        if test_pronunciation == correct_pronun:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def sample_baseline_predictions(sample_count, word_decoder):\n",
    "    sample_indices = random.sample(range(TEST_EXAMPLE_COUNT), sample_count)\n",
    "    for example_idx in sample_indices:\n",
    "        example_char_seq = char_input_test[example_idx:example_idx+1]\n",
    "        predicted_pronun = predict_baseline(example_char_seq, testing_encoder_model, testing_decoder_model)\n",
    "        example_word = word_decoder(example_char_seq)\n",
    "        pred_is_correct = is_correct(example_word, predicted_pronun)\n",
    "        print('✅ ' if pred_is_correct else '❌ ', example_word,'-->', predicted_pronun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "7062efa18b14ae22cdefb152e0e13d58917c8c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/anirudhkamath/.conda/envs/pron/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TEST_EXAMPLE_COUNT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0eb55f7b199e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASELINE_MODEL_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# also loads weights for testing models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_baseline_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_matrix_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e36ef7f9c3ed>\u001b[0m in \u001b[0;36msample_baseline_predictions\u001b[0;34m(sample_count, word_decoder)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_baseline_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_EXAMPLE_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mexample_char_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEST_EXAMPLE_COUNT' is not defined"
     ]
    }
   ],
   "source": [
    "training_model.load_weights(BASELINE_MODEL_WEIGHTS)  # also loads weights for testing models\n",
    "# sample_baseline_predictions(10, one_hot_matrix_to_word)\n",
    "predict_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e3c452bc62a7a843cbf01e32850875af391d540"
   },
   "source": [
    "These all look pretty good. Even the incorrect predictions seem reasonable.\n",
    "\n",
    "## Evaluation\n",
    "We'll use 3 different metrics to evaluate our model. \n",
    "\n",
    "**1. Syllable Count Accuracy**: remember one of the original goals of this project was to be able to count the number of syllables for words not found in the dictionary. Getting a syllable count from a phonetic spelling is as easy as counting the phonemes with stress markers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "5d95b69e675cfcafc4de389a8e2b1df8276cf878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLED -- 1 syllables\n",
      "EDIT -- 2 syllables\n",
      "ILLICITLY -- 4 syllables\n"
     ]
    }
   ],
   "source": [
    "def syllable_count(phonetic_sp): \n",
    "    count = 0\n",
    "    for phone in phonetic_sp.split(): \n",
    "        if phone[-1].isdigit():\n",
    "            count += 1 \n",
    "    return count\n",
    "\n",
    "# Examples:\n",
    "for ex_word in list(phonetic_dict.keys())[:3]:\n",
    "    print(ex_word, '--', syllable_count(phonetic_dict[ex_word][0]), 'syllables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b34b3daefc098ad485cafdddd7ce7d317eb4f52"
   },
   "source": [
    "**2. Perfect Accuracy**: % of test examples where every predicted phoneme and stress marker is correct and in the correct order. \n",
    "\n",
    "**3. Average Bleu Score:** will give our model credit for predictions that are close. A perfect prediction is a 1.0 and a total mismatch is a 0.0. This metric is often used to evaluate language translation, which, if you think about it, is pretty similar to pronunciation prediction. Read more about it [here](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "3406df17756ec7b8266c39a84e8e2a8ee0d107cd"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def is_syllable_count_correct(word, test_pronunciation):\n",
    "    correct_pronuns = phonetic_dict[word]\n",
    "    for correct_pronun in correct_pronuns:\n",
    "        if syllable_count(test_pronunciation) == syllable_count(correct_pronun):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    "def bleu_score(word,test_pronunciation):\n",
    "    references = [pronun.split() for pronun in phonetic_dict[word]]\n",
    "    smooth = SmoothingFunction().method1\n",
    "    return sentence_bleu(references, test_pronunciation.split(), smoothing_function=smooth)\n",
    "\n",
    "\n",
    "def evaluate(test_examples, encoder, decoder, word_decoder, predictor):\n",
    "    correct_syllable_counts = 0\n",
    "    perfect_predictions = 0\n",
    "    bleu_scores = []\n",
    "    \n",
    "    for example_idx in range(TEST_EXAMPLE_COUNT):\n",
    "        example_char_seq = test_examples[example_idx:example_idx+1]\n",
    "        predicted_pronun = predictor(example_char_seq, encoder, decoder)\n",
    "        example_word = word_decoder(example_char_seq)\n",
    "        \n",
    "        perfect_predictions += is_correct(example_word,predicted_pronun)\n",
    "        correct_syllable_counts += is_syllable_count_correct(example_word,predicted_pronun)\n",
    "\n",
    "        bleu = bleu_score(example_word,predicted_pronun)\n",
    "        bleu_scores.append(bleu)\n",
    "        \n",
    "    syllable_acc = correct_syllable_counts / TEST_EXAMPLE_COUNT\n",
    "    perfect_acc = perfect_predictions / TEST_EXAMPLE_COUNT\n",
    "    avg_bleu_score = np.mean(bleu_scores)\n",
    "    \n",
    "    return syllable_acc, perfect_acc, avg_bleu_score\n",
    "\n",
    "\n",
    "def print_results(model_name, syllable_acc, perfect_acc, avg_bleu_score):\n",
    "    print(model_name)\n",
    "    print('-'*20)\n",
    "    print('Syllable Accuracy: %s%%' % round(syllable_acc*100, 1))\n",
    "    print('Perfect Accuracy: %s%%' % round(perfect_acc*100, 1))\n",
    "    print('Bleu Score: %s' % round(avg_bleu_score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "712d73c3fb49e3969dd9757ddd4ab3f4e0b75047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model\n",
      "--------------------\n",
      "Syllable Accuracy: 65.4%\n",
      "Perfect Accuracy: 26.7%\n",
      "Bleu Score: 0.4617\n"
     ]
    }
   ],
   "source": [
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    char_input_test, testing_encoder_model, testing_decoder_model, one_hot_matrix_to_word, predict_baseline)\n",
    "print_results('Baseline Model',syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6e8b54c377afd7cc5a6cd584bd0b0d48083b52a3"
   },
   "source": [
    "Great! Our scores so far are decent. Let's see if we can find a few ways to improve on our baseline model. \n",
    "\n",
    "Before we do, let's free up some memory by removing our baseline model from the Tensorflow graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "6e7451096046032e7296e12f229301c54c4b69d0"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e2bfd192e809282e736ddf8cd2df248b744e819"
   },
   "source": [
    "# Character & Phoneme Embeddings\n",
    "Instead of representing letters and phonemes as 1-hot vectors, we can use an **embedding**[[video](https://www.coursera.org/learn/nlp-sequence-models/lecture/K604Z/embedding-matrix),[blog](https://www.quora.com/What-is-word-embedding-in-deep-learning)] so our model will learn it's own representations of each symbol. Embeddings are more descriptive representations than 1-hot vectors. Think about how the letter 'c' sometimes sounds like a 'k' and other times sounds like an 's'. In theory, our embedding layer should learn these kinds of relationships. Hopefully this will help improve our scores.\n",
    "\n",
    "Keras's `Embedding` layer will convert id's to embeddings for us so we need to change the way we represent our word data. This time we'll just store character & phoneme ids instead of their 1-hot representations. For simplicity, we'll continue to use the 1-hot representation of phonemes for our decoders's output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "77b6604223e43dd722e6edf2e7948a7d3d152f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Word Matrix Shape:  (5321, 17)\n",
      "Embedding Phoneme Matrix Shape:  (5321, 18)\n"
     ]
    }
   ],
   "source": [
    "def dataset_for_embeddings():\n",
    "    char_seqs = []\n",
    "    phone_seqs = []\n",
    "    \n",
    "    for word,pronuns in phonetic_dict.items():\n",
    "        word_matrix = np.zeros((MAX_CHAR_SEQ_LEN))\n",
    "        for t,char in enumerate(word):\n",
    "            word_matrix[t] = char_to_id[char]\n",
    "        for pronun in pronuns:\n",
    "            pronun_matrix = np.zeros((MAX_PHONE_SEQ_LEN))\n",
    "            phones = [START_PHONE_SYM] + pronun.split() + [END_PHONE_SYM]\n",
    "            for t, phone in enumerate(phones):\n",
    "                pronun_matrix[t] = phone_to_id[phone]\n",
    "                \n",
    "            char_seqs.append(word_matrix)\n",
    "            phone_seqs.append(pronun_matrix)\n",
    "    \n",
    "    return np.array(char_seqs), np.array(phone_seqs)\n",
    "\n",
    "            \n",
    "char_emb_matrix, phone_emb_matrix = dataset_for_embeddings()        \n",
    "\n",
    "print('Embedding Word Matrix Shape: ', char_emb_matrix.shape)\n",
    "print('Embedding Phoneme Matrix Shape: ', phone_emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47c498dfcb64e1d44931b84f70cc89db4877f79b"
   },
   "source": [
    "We need to redo the train/test split. Notice that `random_state` is the same as before so the examples in each set will be the same. It also means we don't need to redo the split for our 1-hot (decoder output) phoneme matrix since we're reusing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "b1c3a8b823d531478b468451b3c531b2c07eb185"
   },
   "outputs": [],
   "source": [
    "(emb_char_input_train, emb_char_input_test, \n",
    " emb_phone_input_train, emb_phone_input_test) = train_test_split(\n",
    "    char_emb_matrix, phone_emb_matrix, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5edd80b63d4cabbd7d8038a09f9ebeebb44adf56"
   },
   "source": [
    "Finally we can add the new embedding layers to our baseline model. Since they add a lot more trainable parameters to our network it's going to be easier to overfit. Let's try to avoid that by adding a few dropout layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "69212b2d94ce444d6dbf0b5a5ee09aaa66a0e4d3"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dropout, Activation\n",
    "\n",
    "def embedding_model(hidden_nodes = 256, emb_size = 256):\n",
    "    \n",
    "    # Shared Components - Encoder\n",
    "    char_inputs = Input(shape=(None,))\n",
    "    char_embedding_layer = Embedding(CHAR_TOKEN_COUNT, emb_size, input_length=MAX_CHAR_SEQ_LEN, mask_zero=True)\n",
    "    encoder = LSTM(hidden_nodes, return_state=True, recurrent_dropout=0.1)\n",
    "    \n",
    "    # Shared Components - Decoder\n",
    "    phone_inputs = Input(shape=(None,))\n",
    "    phone_embedding_layer = Embedding(PHONE_TOKEN_COUNT, emb_size, mask_zero=True)\n",
    "    decoder = LSTM(hidden_nodes, return_sequences=True, return_state=True, recurrent_dropout=0.1)\n",
    "    decoder_dense = Dense(PHONE_TOKEN_COUNT, activation='softmax')\n",
    "    \n",
    "    # Training Model\n",
    "    char_embeddings = char_embedding_layer(char_inputs)\n",
    "    char_embeddings = Activation('relu')(char_embeddings)\n",
    "    char_embeddings = Dropout(0.5)(char_embeddings)\n",
    "    _, state_h, state_c = encoder(char_embeddings)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    phone_embeddings = phone_embedding_layer(phone_inputs)\n",
    "    phone_embeddings = Activation('relu')(phone_embeddings)\n",
    "    phone_embeddings = Dropout(0.5)(phone_embeddings)\n",
    "    decoder_outputs, _, _ = decoder(phone_embeddings, initial_state=encoder_states)\n",
    "    decoder_outputs = Dropout(0.5)(decoder_outputs)\n",
    "    phone_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    training_model = Model([char_inputs, phone_inputs], phone_outputs)\n",
    "    \n",
    "    # Testing Model - Encoder\n",
    "    testing_encoder_model = Model(char_inputs, encoder_states)\n",
    "    \n",
    "    # Testing Model - Decoder\n",
    "    decoder_state_input_h = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_input_c = Input(shape=(hidden_nodes,))\n",
    "    decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    test_decoder_outputs, decoder_state_h, decoder_state_c = decoder(phone_embeddings, initial_state=decoder_state_inputs)\n",
    "    decoder_states = [decoder_state_h, decoder_state_c]\n",
    "    test_phone_outputs = decoder_dense(test_decoder_outputs)\n",
    "    \n",
    "    testing_decoder_model = Model([phone_inputs] + decoder_state_inputs, [test_phone_outputs] + decoder_states)\n",
    "    \n",
    "    return training_model, testing_encoder_model, testing_decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90ee3d76d8e89c539dd3c4e84ecf727ea2c2b59c"
   },
   "source": [
    "## Training (Embedding Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "d5e10c979610df96df9d703c2a866644d89d32d3"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_WEIGHTS = os.path.join(\n",
    "    '../input', 'predicting-english-pronunciations-model-weights', 'embedding_model_weights.hdf5')\n",
    "emb_training_model, emb_testing_encoder_model, emb_testing_decoder_model = embedding_model()\n",
    "if not IS_KAGGLE:\n",
    "    train(emb_training_model, EMBEDDING_MODEL_WEIGHTS, emb_char_input_train, emb_phone_input_train, phone_output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c5764dbe8ab16515ad0d4dcd290b1c03a189d7a"
   },
   "source": [
    "## Evaluation (Embedding Model)\n",
    "To evaluate our embedding model we need to add a new helper method to convert id based representations back into words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "4ae7c598a24ddac542772b2cadf04c9a074b6624"
   },
   "outputs": [],
   "source": [
    "def id_vec_to_word(emb_char_seq):\n",
    "    word = ''\n",
    "    for char_id in emb_char_seq[0]:\n",
    "        char = id_to_char[char_id]\n",
    "        word += char\n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d09db9f558d34c30775fbd849769c7a35ed43e7"
   },
   "source": [
    "We'll also rewrite the prediction method to work with id representations (instead of 1-hot) before we score our new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "3b66de8ccfddccdebdf08c905cd6edc2a143b8a0"
   },
   "outputs": [],
   "source": [
    "def predict_emb(input_char_seq, encoder, decoder):\n",
    "    state_vectors = encoder.predict(input_char_seq) \n",
    "    output_phone_seq = np.array([[phone_to_id[START_PHONE_SYM]]])\n",
    "    \n",
    "    end_found = False \n",
    "    pronunciation = '' \n",
    "    while not end_found:\n",
    "        decoder_output, h, c = decoder.predict([output_phone_seq] + state_vectors)\n",
    "        \n",
    "        # Predict the phoneme with the highest probability\n",
    "        predicted_phone_idx = np.argmax(decoder_output[0, -1, :])\n",
    "        predicted_phone = id_to_phone[predicted_phone_idx]\n",
    "        \n",
    "        pronunciation += predicted_phone + ' '\n",
    "        \n",
    "        if predicted_phone == END_PHONE_SYM or len(pronunciation.split()) > MAX_PHONE_SEQ_LEN: \n",
    "            end_found = True\n",
    "        \n",
    "        # Setup inputs for next time step\n",
    "        output_phone_seq = np.array([[predicted_phone_idx]])\n",
    "        state_vectors = [h, c]\n",
    "        \n",
    "    return pronunciation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_uuid": "681f2a5b53cb6fa60707f8fe055ea2947219fbf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model\n",
      "--------------------\n",
      "Syllable Accuracy: 95.6%\n",
      "Perfect Accuracy: 65.3%\n",
      "Bleu Score: 0.754\n"
     ]
    }
   ],
   "source": [
    "emb_training_model.load_weights(EMBEDDING_MODEL_WEIGHTS) # also loads weights for testing models\n",
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    emb_char_input_test, emb_testing_encoder_model, emb_testing_decoder_model, id_vec_to_word, predict_emb)\n",
    "print_results('Embedding Model', syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1596637e86ab8bbf41279e5a352bf100273097e3"
   },
   "source": [
    "Nice! Adding embedding layers and dropout resulted in a solid improvement on all our metrics. \n",
    "\n",
    "### Visualizing the Embeddings\n",
    "For fun, let's extract the embeddings the model learned and visualize them with t-SNE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "253b5d0fdb3a850a06c6e67ab72ab165db901e27"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_embeddings(embeddings, symbols, perplexity):\n",
    "    embeddings_in_2D = TSNE(n_components=2,perplexity=perplexity).fit_transform(embeddings)\n",
    "    embeddings_in_2D[:,0] = embeddings_in_2D[:,0] / np.max(np.abs(embeddings_in_2D[:,0]))\n",
    "    embeddings_in_2D[:,1] = embeddings_in_2D[:,1] / np.max(np.abs(embeddings_in_2D[:,1]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(6,6)\n",
    "    ax.scatter(embeddings_in_2D[:,0], embeddings_in_2D[:,1],c='w')\n",
    "\n",
    "    for i, letter in enumerate(symbols):\n",
    "        ax.annotate(letter, (embeddings_in_2D[i,0],embeddings_in_2D[i,1]), fontsize=12, fontweight='bold')\n",
    "        \n",
    "        \n",
    "char_embedding = emb_training_model.layers[2].get_weights()[0]\n",
    "plot_embeddings(char_embedding, char_to_id.keys(), 5)\n",
    "\n",
    "phone_embedding = emb_training_model.layers[3].get_weights()[0]\n",
    "plot_embeddings(phone_embedding, phone_to_id.keys(), 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "963a7a00e49fe85b1b28e16a860b5d1a7c5053d1"
   },
   "source": [
    "Pretty cool. Notice how letters and phonemes with similar sounds are grouped together.\n",
    "\n",
    "Let's reset the Tensorflow graph again and keep going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "b58e81d3f5bd8a3966bd7ccff8ca07789cd2982e"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "378feed8c200e09ff85cabd98f10eba1aef7c58b"
   },
   "source": [
    "# Bidirectional Encoder & Attention Decoder\n",
    "Up to this point, our RNN models have only run in one direction and the only connection between our encoder and decoder has been the 2 state variables we pass between them (from end of the encoder --> start of the decoder). For longer words & pronunciations, those state variables might not be enough to capture the entire word and the singal from the encoder has the potential to get lost. \n",
    "\n",
    "An Attention Mechanism[video,blog] is a way to avoid this problem. We'll need to make some big changes to our model's structure. We'll be using the encoder's outputs instead of it's internal state variables. This makes it easy to make the encoder bidirectional[video,blog]. Having info about the next as well as the previous characters in a word should result in better encodings at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "2073ed67e49f7cacc3b3ce0641bf24e247a97748"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Multiply, Reshape, RepeatVector, Lambda, Flatten\n",
    "from keras.activations import softmax\n",
    "\n",
    "def attention_model(hidden_nodes = 256, emb_size = 256):\n",
    "    # Attention Mechanism Layers\n",
    "    attn_repeat = RepeatVector(MAX_CHAR_SEQ_LEN)\n",
    "    attn_concat = Concatenate(axis=-1)\n",
    "    attn_dense1 = Dense(128, activation=\"tanh\")\n",
    "    attn_dense2 = Dense(1, activation=\"relu\")\n",
    "    attn_softmax = Lambda(lambda x: softmax(x,axis=1))\n",
    "    attn_dot = Dot(axes = 1)\n",
    "    \n",
    "    def get_context(encoder_outputs, h_prev):\n",
    "        h_prev = attn_repeat(h_prev)\n",
    "        concat = attn_concat([encoder_outputs, h_prev])\n",
    "        e = attn_dense1(concat)\n",
    "        e = attn_dense2(e)\n",
    "        attention_weights = attn_softmax(e)\n",
    "        context = attn_dot([attention_weights, encoder_outputs])\n",
    "        return context\n",
    "    \n",
    "    # Shared Components - Encoder\n",
    "    char_inputs = Input(shape=(None,))\n",
    "    char_embedding_layer = Embedding(CHAR_TOKEN_COUNT, emb_size, input_length=MAX_CHAR_SEQ_LEN)\n",
    "    encoder = Bidirectional(LSTM(hidden_nodes, return_sequences=True, recurrent_dropout=0.2))\n",
    "    \n",
    "    # Shared Components - Decoder\n",
    "    decoder = LSTM(hidden_nodes, return_state=True, recurrent_dropout=0.2)\n",
    "    phone_embedding_layer = Embedding(PHONE_TOKEN_COUNT, emb_size)\n",
    "    embedding_reshaper = Reshape((1,emb_size,))\n",
    "    context_phone_concat = Concatenate(axis=-1)\n",
    "    context_phone_dense = Dense(hidden_nodes*3, activation=\"relu\")\n",
    "    output_layer = Dense(PHONE_TOKEN_COUNT, activation='softmax')\n",
    "    \n",
    "    # Training Model - Encoder\n",
    "    char_embeddings = char_embedding_layer(char_inputs)\n",
    "    char_embeddings = Activation('relu')(char_embeddings)\n",
    "    char_embeddings = Dropout(0.5)(char_embeddings)\n",
    "    encoder_outputs = encoder(char_embeddings)\n",
    "    \n",
    "    # Training Model - Attention Decoder\n",
    "    h0 = Input(shape=(hidden_nodes,))\n",
    "    c0 = Input(shape=(hidden_nodes,))\n",
    "    h = h0 # hidden state\n",
    "    c = c0 # cell state\n",
    "    \n",
    "    phone_inputs = []\n",
    "    phone_outputs = []\n",
    "    \n",
    "    for t in range(MAX_PHONE_SEQ_LEN):\n",
    "        phone_input = Input(shape=(None,))\n",
    "        phone_embeddings = phone_embedding_layer(phone_input)\n",
    "        phone_embeddings = Dropout(0.5)(phone_embeddings)\n",
    "        phone_embeddings = embedding_reshaper(phone_embeddings)\n",
    "        \n",
    "        context = get_context(encoder_outputs, h)\n",
    "        phone_and_context = context_phone_concat([context, phone_embeddings])\n",
    "        phone_and_context = context_phone_dense(phone_and_context)\n",
    "        \n",
    "        decoder_output, h, c = decoder(phone_and_context, initial_state = [h, c])\n",
    "        decoder_output = Dropout(0.5)(decoder_output)\n",
    "        phone_output = output_layer(decoder_output)\n",
    "        \n",
    "        phone_inputs.append(phone_input)\n",
    "        phone_outputs.append(phone_output)\n",
    "    \n",
    "    training_model = Model(inputs=[char_inputs, h0, c0] + phone_inputs, outputs=phone_outputs)\n",
    "    \n",
    "   # Testing Model - Encoder\n",
    "    testing_encoder_model = Model(char_inputs, encoder_outputs)\n",
    "\n",
    "    # Testing Model - Decoder\n",
    "    test_prev_phone_input = Input(shape=(None,))\n",
    "    test_phone_embeddings = phone_embedding_layer(test_prev_phone_input)\n",
    "    test_phone_embeddings = embedding_reshaper(test_phone_embeddings)\n",
    "    \n",
    "    test_h = Input(shape=(hidden_nodes,), name='test_h')\n",
    "    test_c = Input(shape=(hidden_nodes,), name='test_c')\n",
    "    \n",
    "    test_encoding_input = Input(shape=(MAX_CHAR_SEQ_LEN, hidden_nodes*2,))\n",
    "    test_context = get_context(test_encoding_input, test_h)\n",
    "    test_phone_and_context = Concatenate(axis=-1)([test_context, test_phone_embeddings])\n",
    "    test_phone_and_context = context_phone_dense(test_phone_and_context)\n",
    "        \n",
    "    test_seq, out_h, out_c = decoder(test_phone_and_context, initial_state = [test_h, test_c])\n",
    "    test_out = output_layer(test_seq)\n",
    "    \n",
    "    testing_decoder_model = Model([test_prev_phone_input, test_h, test_c, test_encoding_input], [test_out,out_h,out_c])\n",
    "    \n",
    "    return training_model, testing_encoder_model, testing_decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb2c0ad04be28bc610fba383a64593393d35444c"
   },
   "source": [
    "## Training (Attention Model)\n",
    "Since our model, inputs, and outputs have changed so much from our 2 previous versions we need to slightly rewrite our traing procedure. We'll still stop when we start to overfit or plateau and we'll keep the weights that achieve the best validation set loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "ce8d4e4fc360256d6a83e605c9aab721690ee6ee"
   },
   "outputs": [],
   "source": [
    "def train_attention(model, weights_path, validation_size=0.2, epochs=100):    \n",
    "    h0 = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    c0 = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    inputs = list(emb_phone_input_train.swapaxes(0,1))\n",
    "    outputs = list(phone_output_train.swapaxes(0,1))\n",
    "    \n",
    "    callbacks = []\n",
    "    if validation_size > 0:\n",
    "        checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, save_best_only=True)\n",
    "        stopper = EarlyStopping(monitor='val_loss',patience=3)\n",
    "        callbacks = [checkpointer, stopper]\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit([emb_char_input_train, h0, c0] + inputs, outputs,\n",
    "              batch_size=256,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_size,\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    if validation_size == 0:\n",
    "        model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "6b77340ea8c1ed365dbaa4f06ebc41ebf49be1e3"
   },
   "outputs": [],
   "source": [
    "ATTENTION_MODEL_WEIGHTS = os.path.join(\n",
    "    '../input', 'predicting-english-pronunciations-model-weights', 'attention_model_weights.hdf5')\n",
    "attn_training_model, attn_testing_encoder_model, attn_testing_decoder_model = attention_model()\n",
    "if not IS_KAGGLE:\n",
    "    train_attention(attn_training_model, ATTENTION_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c07a0cc29c571103041d135b8beb752d4f79252"
   },
   "source": [
    "## Evaluation (Attention Model)\n",
    "We also need to make some modifications to our baseline_predict method to get it working with our attention model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "5328137af52032d27e8f681b39b51a5f5bdd5db4"
   },
   "outputs": [],
   "source": [
    "def predict_attention(input_char_seq, encoder, decoder):\n",
    "    encoder_outputs = encoder.predict(input_char_seq) \n",
    "\n",
    "    output_phone_seq = np.array([[phone_to_id[START_PHONE_SYM]]])\n",
    "    \n",
    "    h = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    c = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    \n",
    "    end_found = False \n",
    "    pronunciation = '' \n",
    "    while not end_found:\n",
    "        decoder_output, h, c = decoder.predict([output_phone_seq, h, c, encoder_outputs])\n",
    "        \n",
    "        # Predict the phoneme with the highest probability\n",
    "        predicted_phone_idx = np.argmax(decoder_output[0,:])\n",
    "        predicted_phone = id_to_phone[predicted_phone_idx]\n",
    "        \n",
    "        pronunciation += predicted_phone + ' '\n",
    "        \n",
    "        if predicted_phone == END_PHONE_SYM or len(pronunciation.split()) > MAX_PHONE_SEQ_LEN: \n",
    "            end_found = True\n",
    "        \n",
    "        # Setup inputs for next time step\n",
    "        output_phone_seq = np.array([[predicted_phone_idx]])\n",
    "        \n",
    "    return pronunciation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "bcc56b91956f52ac8b4f4c46687f13d136152bf7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Model\n",
      "--------------------\n",
      "Syllable Accuracy: 97.7%\n",
      "Perfect Accuracy: 70.4%\n",
      "Bleu Score: 0.7909\n"
     ]
    }
   ],
   "source": [
    "attn_training_model.load_weights(ATTENTION_MODEL_WEIGHTS) # also loads weights for testing models\n",
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    emb_char_input_test, attn_testing_encoder_model, attn_testing_decoder_model, id_vec_to_word, predict_attention)\n",
    "print_results('Attention Model', syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd335138e248510ca6b3dc567cd874ebeed98e0a"
   },
   "source": [
    "Awesome, all that extra work appears to have paid off. Again we managed a solid improvement in all of our metrics. \n",
    "\n",
    "## Final Training and Evaluation\n",
    "Now that we know which model works best, how long we can train it before it overfits, and all our other hyper-parameters tuned, let's train one final model on all of our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "80e3220fd1ef113f42201d4ac38558fb6e5d3c3c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "FINAL_ATTENTION_MODEL_WEIGHTS = os.path.join(\n",
    "    '../input', 'predicting-english-pronunciations-model-weights', 'final_attention_model_weights.hdf5')\n",
    "attn_training_model, attn_testing_encoder_model, attn_testing_decoder_model = attention_model()\n",
    "if not IS_KAGGLE:\n",
    "    train_attention(attn_training_model, FINAL_ATTENTION_MODEL_WEIGHTS, validation_size=0.0, epochs=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "0b078b0a14e8f296d7c89304945d66884b236ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Attention Model\n",
      "--------------------\n",
      "Syllable Accuracy: 97.4%\n",
      "Perfect Accuracy: 73.4%\n",
      "Bleu Score: 0.8095\n"
     ]
    }
   ],
   "source": [
    "attn_training_model.load_weights(FINAL_ATTENTION_MODEL_WEIGHTS) # also loads weights for testing models\n",
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    emb_char_input_test, attn_testing_encoder_model, attn_testing_decoder_model, id_vec_to_word, predict_attention)\n",
    "print_results('Final Attention Model', syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1fc555938665c586d8c740055c39aa9e4d73391e"
   },
   "source": [
    "Our numbers are looking pretty good, but we've still got 1 trick left up our sleeve...\n",
    "\n",
    "# Beamsearch\n",
    "So far, when we make predictions, we choose the phoneme with the highest probability at each timestep and then move on. But what we *really* want is the sequence of phonemes with the highest probability overall. If we make the wrong choice early on, we can easily end up with a less-than-optimal prediction and we'd never know it! One solution would be to search the entire output space and choose the best of all possible sequences. This would guarantee we find the most likely sequence (at least according to our model) but would take *forever* and involve a lot of wasted effort.\n",
    "\n",
    "Instead we can use Beamsearch[[video](https://www.coursera.org/learn/nlp-sequence-models/lecture/4EtHZ/beam-search),[blog](https://hackernoon.com/beam-search-a-search-strategy-5d92fb7817f)] which sort of falls between the two extremes. At each timestep, we keep the *k* most likely sequences and the move on. Increasing the value of *k* means we're more likely to find the optimal sequence but increases the search time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "3a829e3146d7af2cb3a4a4aa97a90a0ce62a21cd"
   },
   "outputs": [],
   "source": [
    "def predict_beamsearch(input_char_seq, encoder, decoder, k=3):\n",
    "    a = encoder.predict(input_char_seq) \n",
    "    \n",
    "    s = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    c = np.zeros((emb_char_input_train.shape[0], 256))\n",
    "    \n",
    "    all_seqs = []\n",
    "    all_seq_scores = []\n",
    "    \n",
    "    live_seqs = [[phone_to_id[START_PHONE_SYM]]]\n",
    "    live_scores = [0]\n",
    "    live_states = [[s,c]]\n",
    "\n",
    "    while len(live_seqs) > 0: \n",
    "        new_live_seqs = [] \n",
    "        new_live_scores = [] \n",
    "        new_live_states = []\n",
    "        \n",
    "        for sidx,seq in enumerate(live_seqs):\n",
    "            target_seq = np.array([[seq[-1]]])\n",
    "            output_token_probs, s, c = decoder.predict([target_seq] + live_states[sidx] + [a])\n",
    "            \n",
    "            best_token_indicies = output_token_probs[0,:].argsort()[-k:]\n",
    "\n",
    "            for token_index in best_token_indicies:\n",
    "                new_seq = seq + [token_index]\n",
    "                prob = output_token_probs[0,:][token_index]\n",
    "                new_seq_score = live_scores[sidx] - np.log(prob)\n",
    "                if id_to_phone[token_index] == END_PHONE_SYM or len(new_seq) > MAX_PHONE_SEQ_LEN:\n",
    "                    all_seqs.append(new_seq) \n",
    "                    all_seq_scores.append(new_seq_score) \n",
    "                    continue\n",
    "                new_live_seqs.append(new_seq)\n",
    "                new_live_scores.append(new_seq_score)\n",
    "                new_live_states.append([s, c])\n",
    "                \n",
    "        while len(new_live_scores) > k:\n",
    "            worst_seq_score_idx = np.array(new_live_scores).argsort()[-1] \n",
    "            del new_live_seqs[worst_seq_score_idx]\n",
    "            del new_live_scores[worst_seq_score_idx]\n",
    "            del new_live_states[worst_seq_score_idx]\n",
    "            \n",
    "        live_seqs = new_live_seqs\n",
    "        live_scores = new_live_scores\n",
    "        live_states = new_live_states\n",
    "        \n",
    "    best_idx = np.argmin(all_seq_scores)\n",
    "    score = all_seq_scores[best_idx]\n",
    "    \n",
    "    pronunciation = ''\n",
    "    for i in all_seqs[best_idx]:\n",
    "        pronunciation += id_to_phone[i] + ' '\n",
    "    \n",
    "    return pronunciation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "1a1733f64c0cde7db12ff07a7302e8123cb0b2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Attention Model + Beamsearch\n",
      "--------------------\n",
      "Syllable Accuracy: 97.7%\n",
      "Perfect Accuracy: 74.3%\n",
      "Bleu Score: 0.8161\n"
     ]
    }
   ],
   "source": [
    "syllable_acc, perfect_acc, avg_bleu_score = evaluate(\n",
    "    emb_char_input_test, attn_testing_encoder_model, attn_testing_decoder_model, id_vec_to_word, predict_beamsearch)\n",
    "print_results('Final Attention Model + Beamsearch', syllable_acc, perfect_acc, avg_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3973aae34b579d42272eb5f087122ec712e1c09c",
    "collapsed": true
   },
   "source": [
    "# Results\n",
    "Here are the final results I obtained locally on the complete test set (~20k examples):\n",
    "\n",
    "| Model        | Baseline | Embedding | Attention | Final Attention | Final Attention + Beamsearch |\n",
    "|--------------|----------|-----------|-----------|-----------------|------------------------------|\n",
    "| Syllable Acc | 91.3        |   96.0        |   96.8        |     97.1            | **98.1**                             |\n",
    "| Perfect Acc  | 51.9         |    61.5       |    66.6      |     67.6            |   **75.4**                           |\n",
    "| Bleu Score   | 0.654         |   0.734        |     0.770      |      0.778           | **0.829**                           |\n",
    "\n",
    "English is a weird language. Even native speakers mis-pronounce words that are new to them. Pronunciation rules are complicated and sometimes don't make any sense. Just check out [this video](https://www.youtube.com/watch?v=1edPxKqiptw) for a few examples. 75.4% accuracy might not seem that high, but all things considered, I think it's a respectable score. \n",
    "\n",
    " ## Sampling Incorrect Predictions\n",
    " Let's take a look at some of the words our model is getting wrong:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "05c3165d086ab6c8027a57cad16c4ea442b65e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌  ALESI --> AH0 L EH1 S IY0\n",
      "❌  MOREHEAD --> M AO1 R HH EH2 D\n",
      "❌  SALIM --> S AA1 L IH0 M\n",
      "❌  DICEON --> D IH1 SH AH0 N\n",
      "❌  PHOTOCOPIERS --> F OW2 T OW0 K AA1 P IY0 ER0 Z\n",
      "❌  LEMONDS --> L AH0 M AA1 N D Z\n",
      "❌  ATA --> AE1 T AH0\n",
      "❌  AMPERAGE --> AE1 M P R IH0 JH\n",
      "❌  ANATOLY --> AH0 N AE1 T AH0 L IY0\n",
      "❌  PERSAUD --> P ER0 S AO1 D\n"
     ]
    }
   ],
   "source": [
    "def display_wrong_predictions(sample_count, word_decoder, encoder, decoder):\n",
    "    found = 0\n",
    "    while found < sample_count:\n",
    "        sample_index = random.sample(range(TEST_EXAMPLE_COUNT), 1)[0]\n",
    "        example_char_seq = emb_char_input_test[sample_index:sample_index+1]\n",
    "        predicted_pronun = predict_attention(example_char_seq, encoder, decoder)\n",
    "        example_word = word_decoder(example_char_seq)\n",
    "        pred_is_correct = is_correct(example_word,predicted_pronun)\n",
    "        if not pred_is_correct:\n",
    "            found += 1\n",
    "            print('❌ ', example_word,'-->',predicted_pronun)\n",
    "            \n",
    "display_wrong_predictions(10, id_vec_to_word, attn_testing_encoder_model, attn_testing_decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.id_vec_to_word(emb_char_seq)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_vec_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding words that rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAH SICKA THAN YOUR AVERAGE',\n",
       " 'POPPA TWIST CABBAGE OFF INSTINCT',\n",
       " 'NIGGAS DONT THINK SHIT STINK PINK GATORS',\n",
       " 'MY DETROIT PLAYERS',\n",
       " 'TIMBS FOR MY HOOLIGANS IN BROOKLYN',\n",
       " 'DEAD RIGHT IF THE HEAD RIGHT BIGGIE THERE ERYNIGHT',\n",
       " 'POPPA BEEN SMOOTH SINCE DAYS OF UNDERROOS',\n",
       " 'NEVER LOSE NEVER CHOOSE TO BRUISE CREWS WHO',\n",
       " 'DO SOMETHING TO US TALK GO THROUGH US',\n",
       " 'GIRLS WALK TO US WANNA DO US SCREW US',\n",
       " 'WHO US YEAH POPPA AND PUFF',\n",
       " 'CLOSE LIKE STARSKY AND HUTCH STICK THE CLUTCH',\n",
       " 'DARE I SQUEEZE THREE AT YOUR CHERRY M THREE',\n",
       " 'BANG EVERY MC EASILY BUSILY',\n",
       " 'RECENTLY NIGGAS FRONTIN AINT SAYIN NUTTIN SO I JUST',\n",
       " 'SPEAK MY PIECE KEEP MY PIECE',\n",
       " 'CUBANS WITH THE JESUS PIECE WITH MY PEEPS',\n",
       " 'PACKIN ASKIN WHO WANT IT YOU GOT IT NIGGA FLAUNT IT',\n",
       " 'THAT BROOKLYN BULLSHIT WE ON IT']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = '''\n",
    "Hah, sicka than your average\n",
    "Poppa twist cabbage off instinct\n",
    "Niggas don't think shit stink, pink gators,\n",
    "My Detroit players\n",
    "Timbs for my hooligans in Brooklyn\n",
    "Dead right, if the head right, Biggie there ery'night\n",
    "Poppa been smooth since days of Underroos\n",
    "Never lose, never choose to, bruise crews who\n",
    "Do something to us, talk go through us\n",
    "Girls walk to us, wanna do us, screw us\n",
    "Who us? Yeah, Poppa and Puff (hehehe)\n",
    "Close like Starsky and Hutch, stick the clutch\n",
    "Dare I squeeze three at your cherry M Three (Take that, take that, take that, haha!)\n",
    "Bang every MC easily, busily\n",
    "Recently niggas frontin ain't sayin' nuttin' (nope) so I just\n",
    "Speak my piece, (c'mon) keep my piece\n",
    "Cubans with the Jesus piece (thank you God), with my peeps\n",
    "Packin', askin' who want it, you got it nigga flaunt it\n",
    "That Brooklyn bullshit, we on it\n",
    "'''\n",
    "lyrics = lyrics.split('\\n')\n",
    "# Remove text in parentheses\n",
    "lyrics = [re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x) for x in lyrics]\n",
    "# Only keep alphanumeric\n",
    "lyrics = [re.sub(r'\\W+', '', lyric.replace(' ', '_')) for lyric in lyrics]\n",
    "lyrics = filter(lambda x: x != '', lyrics)\n",
    "lyrics = map(lambda x: x.replace('_', ' ').replace('  ', ' ').strip().upper(), lyrics)\n",
    "lyrics = list(lyrics)\n",
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAH SICKA THAN YOUR AVERAGE\n",
      "['HH', 'AA3', 'S', 'IH1', 'K', 'AH0', 'TH', 'AE3', 'N', 'Y', 'UH3', 'R', 'AE1', 'V', 'R', 'IH0', 'JH']\n",
      "[('AA', 3), ('IH', 1), ('AH', 0), ('AE', 3), ('UH', 3), ('AE', 1), ('IH', 0)]\n",
      "\n",
      "\n",
      "POPPA TWIST CABBAGE OFF INSTINCT\n",
      "['P', 'AA1', 'P', 'AH0', 'T', 'W', 'IH3', 'S', 'T', 'K', 'AE1', 'B', 'IH0', 'JH', 'AO3', 'F', 'IH1', 'N', 'S', 'T', 'IH0', 'NG', 'K', 'T']\n",
      "[('AA', 1), ('AH', 0), ('IH', 3), ('AE', 1), ('IH', 0), ('AO', 3), ('IH', 1), ('IH', 0)]\n",
      "\n",
      "\n",
      "NIGGAS DONT THINK SHIT STINK PINK GATORS\n",
      "['N', 'IH1', 'G', 'AH0', 'Z', 'D', 'AA3', 'N', 'T', 'TH', 'IH3', 'NG', 'K', 'SH', 'IH3', 'T', 'S', 'T', 'IH3', 'NG', 'K', 'P', 'IH3', 'NG', 'K', 'G', 'EY1', 'T', 'ER0', 'Z']\n",
      "[('IH', 1), ('AH', 0), ('AA', 3), ('IH', 3), ('IH', 3), ('IH', 3), ('IH', 3), ('EY', 1), ('ER', 0)]\n",
      "\n",
      "\n",
      "MY DETROIT PLAYERS\n",
      "['M', 'AY3', 'D', 'IH0', 'T', 'R', 'OY1', 'T', 'P', 'L', 'EY1', 'ER0', 'Z']\n",
      "[('AY', 3), ('IH', 0), ('OY', 1), ('EY', 1), ('ER', 0)]\n",
      "\n",
      "\n",
      "TIMBS FOR MY HOOLIGANS IN BROOKLYN\n",
      "['T', 'IH3', 'M', 'Z', 'F', 'AO3', 'R', 'M', 'AY3', 'HH', 'UW1', 'L', 'IH0', 'G', 'AH0', 'N', 'Z', 'IH3', 'N', 'B', 'R', 'UH1', 'K', 'L', 'IH0', 'N']\n",
      "[('IH', 3), ('AO', 3), ('AY', 3), ('UW', 1), ('IH', 0), ('AH', 0), ('IH', 3), ('UH', 1), ('IH', 0)]\n",
      "\n",
      "\n",
      "DEAD RIGHT IF THE HEAD RIGHT BIGGIE THERE ERYNIGHT\n",
      "['D', 'EH3', 'D', 'R', 'AY3', 'T', 'IH3', 'F', 'DH', 'IY3', 'HH', 'EH3', 'D', 'R', 'AY3', 'T', 'B', 'IH1', 'G', 'IY0', 'DH', 'EH3', 'R', 'EH1', 'R', 'IY0', 'N', 'AY2', 'T']\n",
      "[('EH', 3), ('AY', 3), ('IH', 3), ('IY', 3), ('EH', 3), ('AY', 3), ('IH', 1), ('IY', 0), ('EH', 3), ('EH', 1), ('IY', 0), ('AY', 2)]\n",
      "\n",
      "\n",
      "POPPA BEEN SMOOTH SINCE DAYS OF UNDERROOS\n",
      "['P', 'AA1', 'P', 'AH0', 'B', 'IY3', 'N', 'S', 'M', 'UW3', 'TH', 'S', 'IH3', 'N', 'S', 'D', 'EY3', 'Z', 'AO3', 'F', 'AH2', 'N', 'D', 'ER0', 'R', 'UW1', 'Z']\n",
      "[('AA', 1), ('AH', 0), ('IY', 3), ('UW', 3), ('IH', 3), ('EY', 3), ('AO', 3), ('AH', 2), ('ER', 0), ('UW', 1)]\n",
      "\n",
      "\n",
      "NEVER LOSE NEVER CHOOSE TO BRUISE CREWS WHO\n",
      "['N', 'EH1', 'V', 'ER0', 'L', 'OW3', 'Z', 'N', 'EH1', 'V', 'ER0', 'CH', 'UW3', 'Z', 'T', 'UW3', 'B', 'R', 'UW3', 'Z', 'K', 'R', 'UW3', 'Z', 'HH', 'UW3']\n",
      "[('EH', 1), ('ER', 0), ('OW', 3), ('EH', 1), ('ER', 0), ('UW', 3), ('UW', 3), ('UW', 3), ('UW', 3), ('UW', 3)]\n",
      "\n",
      "\n",
      "DO SOMETHING TO US TALK GO THROUGH US\n",
      "['D', 'UW3', 'S', 'AH1', 'M', 'TH', 'IH0', 'NG', 'T', 'UW3', 'AH3', 'S', 'T', 'AO3', 'K', 'G', 'OW3', 'TH', 'R', 'UW3', 'AH3', 'S']\n",
      "[('UW', 3), ('AH', 1), ('IH', 0), ('UW', 3), ('AH', 3), ('AO', 3), ('OW', 3), ('UW', 3), ('AH', 3)]\n",
      "\n",
      "\n",
      "GIRLS WALK TO US WANNA DO US SCREW US\n",
      "['G', 'ER3', 'L', 'Z', 'W', 'AO3', 'K', 'T', 'UW3', 'AH3', 'S', 'W', 'AA1', 'N', 'AH0', 'D', 'UW3', 'AH3', 'S', 'S', 'K', 'R', 'UW3', 'AH3', 'S']\n",
      "[('ER', 3), ('AO', 3), ('UW', 3), ('AH', 3), ('AA', 1), ('AH', 0), ('UW', 3), ('AH', 3), ('UW', 3), ('AH', 3)]\n",
      "\n",
      "\n",
      "WHO US YEAH POPPA AND PUFF\n",
      "['HH', 'UW3', 'AH3', 'S', 'Y', 'IY1', 'AH0', 'P', 'AA1', 'P', 'AH0', 'AE3', 'N', 'D', 'P', 'AH3', 'F']\n",
      "[('UW', 3), ('AH', 3), ('IY', 1), ('AH', 0), ('AA', 1), ('AH', 0), ('AE', 3), ('AH', 3)]\n",
      "\n",
      "\n",
      "CLOSE LIKE STARSKY AND HUTCH STICK THE CLUTCH\n",
      "['K', 'L', 'OW3', 'Z', 'L', 'AY3', 'K', 'S', 'T', 'AA1', 'R', 'S', 'K', 'IY0', 'AE3', 'N', 'D', 'HH', 'AH3', 'CH', 'S', 'T', 'IH3', 'K', 'DH', 'IY3', 'K', 'L', 'AH3', 'CH']\n",
      "[('OW', 3), ('AY', 3), ('AA', 1), ('IY', 0), ('AE', 3), ('AH', 3), ('IH', 3), ('IY', 3), ('AH', 3)]\n",
      "\n",
      "\n",
      "DARE I SQUEEZE THREE AT YOUR CHERRY M THREE\n",
      "['D', 'EH3', 'R', 'AY3', 'S', 'K', 'W', 'IY3', 'Z', 'TH', 'R', 'IY3', 'AE3', 'T', 'Y', 'UH3', 'R', 'CH', 'EH1', 'R', 'IY0', 'EH3', 'M', 'TH', 'R', 'IY3']\n",
      "[('EH', 3), ('AY', 3), ('IY', 3), ('IY', 3), ('AE', 3), ('UH', 3), ('EH', 1), ('IY', 0), ('EH', 3), ('IY', 3)]\n",
      "\n",
      "\n",
      "BANG EVERY MC EASILY BUSILY\n",
      "['B', 'AE3', 'NG', 'EH1', 'V', 'ER0', 'IY0', 'M', 'AH0', 'K', 'IY1', 'Z', 'AH0', 'L', 'IY0', 'B', 'IH1', 'Z', 'AH0', 'L', 'IY0']\n",
      "[('AE', 3), ('EH', 1), ('ER', 0), ('IY', 0), ('AH', 0), ('IY', 1), ('AH', 0), ('IY', 0), ('IH', 1), ('AH', 0), ('IY', 0)]\n",
      "\n",
      "\n",
      "RECENTLY NIGGAS FRONTIN AINT SAYIN NUTTIN SO I JUST\n",
      "['R', 'IY1', 'S', 'AH0', 'N', 'T', 'L', 'IY0', 'N', 'IH1', 'G', 'AH0', 'Z', 'F', 'R', 'AA1', 'N', 'T', 'IH0', 'N', 'EY3', 'N', 'T', 'S', 'EY1', 'IH0', 'N', 'N', 'AH1', 'T', 'IH0', 'N', 'S', 'OW3', 'AY3', 'JH', 'AH3', 'S', 'T']\n",
      "[('IY', 1), ('AH', 0), ('IY', 0), ('IH', 1), ('AH', 0), ('AA', 1), ('IH', 0), ('EY', 3), ('EY', 1), ('IH', 0), ('AH', 1), ('IH', 0), ('OW', 3), ('AY', 3), ('AH', 3)]\n",
      "\n",
      "\n",
      "SPEAK MY PIECE KEEP MY PIECE\n",
      "['S', 'P', 'IY3', 'K', 'M', 'AY3', 'P', 'IY3', 'S', 'K', 'IY3', 'P', 'M', 'AY3', 'P', 'IY3', 'S']\n",
      "[('IY', 3), ('AY', 3), ('IY', 3), ('IY', 3), ('AY', 3), ('IY', 3)]\n",
      "\n",
      "\n",
      "CUBANS WITH THE JESUS PIECE WITH MY PEEPS\n",
      "['K', 'Y', 'UW1', 'B', 'AH0', 'N', 'Z', 'W', 'IH3', 'TH', 'DH', 'IY3', 'JH', 'IY1', 'Z', 'AH0', 'S', 'P', 'IY3', 'S', 'W', 'IH3', 'TH', 'M', 'AY3', 'P', 'IY3', 'P', 'S']\n",
      "[('UW', 1), ('AH', 0), ('IH', 3), ('IY', 3), ('IY', 1), ('AH', 0), ('IY', 3), ('IH', 3), ('AY', 3), ('IY', 3)]\n",
      "\n",
      "\n",
      "PACKIN ASKIN WHO WANT IT YOU GOT IT NIGGA FLAUNT IT\n",
      "['P', 'AE1', 'K', 'IH0', 'N', 'AH0', 'S', 'K', 'IH1', 'N', 'HH', 'UW3', 'W', 'AA3', 'N', 'T', 'IH3', 'T', 'Y', 'UW3', 'G', 'AA3', 'T', 'IH3', 'T', 'N', 'IH1', 'G', 'AH0', 'F', 'L', 'AO3', 'N', 'T', 'IH3', 'T']\n",
      "[('AE', 1), ('IH', 0), ('AH', 0), ('IH', 1), ('UW', 3), ('AA', 3), ('IH', 3), ('UW', 3), ('AA', 3), ('IH', 3), ('IH', 1), ('AH', 0), ('AO', 3), ('IH', 3)]\n",
      "\n",
      "\n",
      "THAT BROOKLYN BULLSHIT WE ON IT\n",
      "['TH', 'AE3', 'T', 'B', 'R', 'UH1', 'K', 'L', 'IH0', 'N', 'B', 'UH1', 'L', 'SH', 'IH2', 'T', 'W', 'IY3', 'AA3', 'N', 'IH3', 'T']\n",
      "[('AE', 3), ('UH', 1), ('IH', 0), ('UH', 1), ('IH', 2), ('IY', 3), ('AA', 3), ('IH', 3)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def predict_pronunciation(word_decoder, encoder, decoder, word, verbose=False):\n",
    "    word_matrix = np.zeros((MAX_CHAR_SEQ_LEN))\n",
    "    for t,char in enumerate(word):\n",
    "        word_matrix[t] = char_to_id[char]\n",
    "    sample_index = random.sample(range(TEST_EXAMPLE_COUNT), 1)[0]\n",
    "    example_char_seq = np.array([word_matrix])\n",
    "    predicted_pronun = predict_attention(example_char_seq, encoder, decoder)\n",
    "    example_word = word_decoder(example_char_seq)\n",
    "    # Distinguish monosyllabic words with a 3 for optional stress\n",
    "    if len(list(filter(lambda x: not x.isalpha() and x != ' ', predicted_pronun))) == 1:\n",
    "        predicted_pronun = predicted_pronun.replace('1', '3')\n",
    "    if verbose:\n",
    "        print(example_word,'-->',predicted_pronun)\n",
    "    \n",
    "    return predicted_pronun\n",
    "\n",
    "pron = partial(predict_pronunciation, id_vec_to_word, attn_testing_encoder_model, attn_testing_decoder_model)\n",
    "predict_sentence = lambda sentence: ' '.join([pron(a) for a in sentence.upper().split(' ')])\n",
    "syllables = lambda syls: list(filter(lambda x: any(map(lambda a: not a.isalpha(), x)), syls))\n",
    "\n",
    "pronunciations = []\n",
    "flow = []\n",
    "\n",
    "for lyric in lyrics:\n",
    "    print(lyric)\n",
    "    syls = predict_sentence(lyric).split(' ')\n",
    "    pronunciations.append(syls)\n",
    "    print(syls)\n",
    "    \n",
    "    syls = list(map(lambda x: (x[:-1], int(x[-1])), syllables(syls)))\n",
    "    flow.append(syls)\n",
    "    print(syls)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-78-91e04d78837e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-78-91e04d78837e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def get_end_rhymes\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_end_rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
